<html lang="en">
<head>
	<meta charset="utf-8">
	<title>Supervised SHMM</title>
	<script src="https://code.jquery.com/jquery-3.2.1.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
	<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
	<link href="https://fonts.googleapis.com/css?family=Open+Sans|Roboto" rel="stylesheet">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
	<link rel="icon" href="favicon.ico">
</head>
<style>
html, body {
	font-family: 'Open Sans', sans-serif;
	width: 100%;
	height: 100%;
}
p {
	font-size: 1.2em;
}
.head {
	padding-top: 50px;
	padding-bottom: 10px;
	padding-left: 30px;
	position: relative;
	width: 100%;
}
.head:after {
	content: "";
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	height: 0.5em;
	border-top: 1px solid black;
	z-index: -1;
}
h1 {
	text-transform: uppercase;
	letter-spacing: 1px;
	font-size: 3.5em;
}
h2 {
	font-weight: bold;
	font-size: 1.8em;
}
h3 {
	font-weight: bold;
	font-size: 1.5em;
}
.page-footer {
	padding: 50px;
	background-color: #eeeeee;
}
#img-dset {
	width: 100%;
	max-width: 980px;
	padding-bottom: 50px;
}
</style>
<body>
<div class="container">
	<div class="head">
		<h1>Supervised SHMM</h1>
	</div>
	<div class="panel-group">
		<p>Detailing implementation of Supervised SHMM from <a href="https://github.com/dpfried/action-segmentation"><i>Learning to Segment Actions from Observation and Narration</i></a></p>
		<div class="panel panel-default">
			<div class="panel-heading"><h2>Toy Dataset</h2></div>
			<div class="panel-body">
				<p>A toy dataset is generated to test the model. Any inputs must take a similar form.</p>
				<hr>
				<img id="img-dset" src="images/dset@2x.png"></img>
				<p><b>labels</b></p>
				<p>Sequence of <i>N</i> action labels.</p>
				<p><b>features</b></p>
				<p>One-hot encodings (plus gaussian noise) of labels.</p>
				<p><b>lengths</b></p>
				<p>Random number from K to N indicating length of sequence. Labels are populated beyond <i>length</i>, but are trimmed downstream.</p>
				<p><b>valid_classes</b></p>
				<p>List of possible classes present in given sequence. This constrains the model to a subset of states.</p>
				<p><b>spans</b></p>
				<p>Masked encoding of labels, for ease of use downstream.</p>
			</div>
		</div>
		<div class="panel panel-default">
			<div class="panel-heading"><h2>Supervised Training</h2></div>
			<div class="panel-body">
				<p>For closed-form supervised training, there are no epochs or algorithms. Instead, the following parameters are inferred directly
					from statistics of the training data:</p>
				<hr>
				<p><b>init_logits</b></p>
				<p><i>n_class</i> vector of initial probabilities, computed as the log of the number of times each class is the starting class.</p>
				<p><b>transition_logits</b></p>
				<p><i>(n_class,  n_class)</i> matrix of transition probablities, computed as the log of the count of each transition, excluding self transitions.</p>
				<p><b>poisson_log_rates</b></p>
				<p><i>n_class</i> vector containing the log of the average length of each class.</p>
				<p><b>gaussian_means</b></p>
				<p><i>(n_class, n_feat)</i> array of the mean feature vector for each class.</p>
				<p><b>gaussian_cov</b></p>
				<p><i>(n_class, n_feat)</i> array of the covariance vector for each class.</p>
			</div>
		</div>
		<div class="panel panel-default">
			<div class="panel-heading"><h2>Inference</h2></div>
			<div class="panel-body">
				<p>The <b>viterbi algorithm</b> is used to compute the most likely state sequence given the feature observations.</p>
				<hr>
				<p><b>init_probs</b></p>
				<p>Likelihood of given class being the starting class.</p>
				<p><b>trans_probs</b></p>
				<p>Likelihood of the given transition from class w to u.</p>
				<p><b>emission_probs</b></p>
				<p>Likelihood of given features for each class.</p>
				<p><b>length_probs</b></p>
				<p>Likelihood of any given length for each class, computed from poisson distribution.</p>
				<hr>
				<p>These parameters are aggregated into a <i>(b, N, K, C, C)</i> matrix of scores, where <i>b</i> is number of batches, <i>N</i> is sequence length,
					<i>K</i> is viterbi sliding window size, and <i>C</i> is number of classes. This matrix can be processed by torch_struct to return state sequence
					probabilities.</p>
			</div>
		</div>
	</div>
	<footer class="page-footer">
		<div class="footer-copyright text-center py-3"><a href="http://dylanebert.com">Dylan Ebert</a></div>
	</footer>
	</div>
</div>
</body>
</html>
